{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12704002,"sourceType":"datasetVersion","datasetId":8028984}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate rouge-score bert-score -q\n\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom datasets import load_dataset\nfrom transformers import GPT2Tokenizer, AutoModelForCausalLM, AutoTokenizer, set_seed\nfrom torch.cuda.amp import autocast, GradScaler\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\n\nimport json, os\nimport evaluate\nimport matplotlib.pyplot as plt\nimport random\n\nset_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:44:12.865230Z","iopub.execute_input":"2025-08-11T11:44:12.865951Z","iopub.status.idle":"2025-08-11T11:44:16.690812Z","shell.execute_reply.started":"2025-08-11T11:44:12.865920Z","shell.execute_reply":"2025-08-11T11:44:16.689882Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"MAX_LEN = 384\nBATCH_SIZE = 8\n\ndataset = load_dataset(\"Anthropic/hh-rlhf\", split=\"train[:3000]\")\n\n# Функция выделения промпта и ответа\ndef split_prompt_answer(text: str):\n    lines = [line.strip() for line in text.strip().split(\"\\n\") if line.strip()]\n    assistant_indices = [i for i, line in enumerate(lines) if line.startswith(\"Assistant:\")]\n    \n    if not assistant_indices:\n        return text, \"\" \n    \n    last_idx = assistant_indices[-1]\n    prompt_lines = lines[:last_idx] + [\"Assistant:\"]\n    prompt = \"\\n\".join(prompt_lines)\n    \n    answer_lines = [lines[last_idx][len(\"Assistant:\"):].strip()] + lines[last_idx+1:]\n    answer = \"\\n\".join(answer_lines).strip()\n    \n    return prompt, answer\n\ndef format_dpo_example(example):\n    chosen_prompt, chosen_answer = split_prompt_answer(example[\"chosen\"])\n    rejected_prompt, rejected_answer = split_prompt_answer(example[\"rejected\"])\n    \n    example[\"prompt_formatted\"] = chosen_prompt  \n    example[\"chosen_formatted\"] = chosen_answer\n    example[\"rejected_formatted\"] = rejected_answer\n    return example\n\ndataset = dataset.map(format_dpo_example)\n\ndataset = dataset.train_test_split(test_size=0.1)\ntrain_data_raw = dataset[\"train\"]\nval_data_raw = dataset[\"test\"]\n\nclass DPOPairDataset(Dataset):\n    def __init__(self, hf_dataset, tokenizer, max_len=MAX_LEN):\n        self.dataset = hf_dataset\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        ex = self.dataset[idx]\n        \n        chosen_enc = self.tokenizer(\n            ex[\"prompt_formatted\"], ex[\"chosen_formatted\"],\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_len,\n            return_tensors=\"pt\",\n            return_overflowing_tokens=False, \n        )\n        rejected_enc = self.tokenizer(\n            ex[\"prompt_formatted\"], ex[\"rejected_formatted\"],\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_len,\n            return_tensors=\"pt\",\n            return_overflowing_tokens=False, \n        )\n    \n        return {\n            \"chosen_input_ids\": chosen_enc.input_ids.squeeze(0),\n            \"chosen_attention_mask\": chosen_enc.attention_mask.squeeze(0),\n            \"rejected_input_ids\": rejected_enc.input_ids.squeeze(0),\n            \"rejected_attention_mask\": rejected_enc.attention_mask.squeeze(0),\n            \"prompt\": ex[\"prompt_formatted\"],\n            \"chosen_answer\": ex[\"chosen_formatted\"],\n        }\n        \ntrain_dataset = DPOPairDataset(train_data_raw, tokenizer)\nval_dataset = DPOPairDataset(val_data_raw, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=torch.cuda.is_available())\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=torch.cuda.is_available())\n\nprint(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:44:19.004338Z","iopub.execute_input":"2025-08-11T11:44:19.004636Z","iopub.status.idle":"2025-08-11T11:44:19.639779Z","shell.execute_reply.started":"2025-08-11T11:44:19.004612Z","shell.execute_reply":"2025-08-11T11:44:19.638963Z"}},"outputs":[{"name":"stdout","text":"Train size: 2700, Validation size: 300\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model_name = \"gpt2\"\nmodel = AutoModelForCausalLM.from_pretrained(model_name).to(device)\nmodel.resize_token_embeddings(len(tokenizer))\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:44:22.672621Z","iopub.execute_input":"2025-08-11T11:44:22.672898Z","iopub.status.idle":"2025-08-11T11:44:23.120337Z","shell.execute_reply.started":"2025-08-11T11:44:22.672878Z","shell.execute_reply":"2025-08-11T11:44:23.119541Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"scaler = GradScaler()\n\ndef train_one_epoch(model, dataloader, optimizer, scaler, device, beta):\n    model.train()\n    total_loss, total_correct, total_samples = 0, 0, 0\n\n    for batch in dataloader:\n        optimizer.zero_grad()\n\n        chosen_input_ids = batch['chosen_input_ids'].to(device)\n        chosen_attention_mask = batch['chosen_attention_mask'].to(device)\n        rejected_input_ids = batch['rejected_input_ids'].to(device)\n        rejected_attention_mask = batch['rejected_attention_mask'].to(device)\n\n        with autocast(dtype=torch.float16):\n            \n            chosen_outputs = model(input_ids=chosen_input_ids, attention_mask=chosen_attention_mask)\n            logp_chosen = -F.cross_entropy(\n                chosen_outputs.logits[:, :-1, :].reshape(-1, chosen_outputs.logits.size(-1)),\n                chosen_input_ids[:, 1:].reshape(-1),\n                reduction=\"none\"\n            ).reshape(chosen_outputs.logits.size(0), -1).sum(dim=1)\n\n            rejected_outputs = model(input_ids=rejected_input_ids, attention_mask=rejected_attention_mask)\n            logp_rejected = -F.cross_entropy(\n                rejected_outputs.logits[:, :-1, :].reshape(-1, rejected_outputs.logits.size(-1)),\n                rejected_input_ids[:, 1:].reshape(-1),\n                reduction=\"none\"\n            ).reshape(rejected_outputs.logits.size(0), -1).sum(dim=1)\n\n            # DPO loss\n            loss = -torch.mean(F.logsigmoid(beta * (logp_chosen - logp_rejected)))\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        # Accuracy\n        correct = (logp_chosen > logp_rejected).sum().item()\n        total_correct += correct\n        total_samples += chosen_input_ids.size(0)\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(dataloader)\n    avg_acc = total_correct / total_samples\n    return avg_loss, avg_acc\n\n\ndef validate(model, dataloader, device, beta):\n    model.eval()\n    total_loss, total_correct, total_samples = 0, 0, 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            chosen_input_ids = batch['chosen_input_ids'].to(device)\n            chosen_attention_mask = batch['chosen_attention_mask'].to(device)\n            rejected_input_ids = batch['rejected_input_ids'].to(device)\n            rejected_attention_mask = batch['rejected_attention_mask'].to(device)\n\n            chosen_outputs = model(input_ids=chosen_input_ids, attention_mask=chosen_attention_mask)\n            logp_chosen = -F.cross_entropy(\n                chosen_outputs.logits[:, :-1, :].reshape(-1, chosen_outputs.logits.size(-1)),\n                chosen_input_ids[:, 1:].reshape(-1),\n                reduction=\"none\"\n            ).reshape(chosen_outputs.logits.size(0), -1).sum(dim=1)\n\n            rejected_outputs = model(input_ids=rejected_input_ids, attention_mask=rejected_attention_mask)\n            logp_rejected = -F.cross_entropy(\n                rejected_outputs.logits[:, :-1, :].reshape(-1, rejected_outputs.logits.size(-1)),\n                rejected_input_ids[:, 1:].reshape(-1),\n                reduction=\"none\"\n            ).reshape(rejected_outputs.logits.size(0), -1).sum(dim=1)\n\n            loss = -torch.mean(F.logsigmoid(beta * (logp_chosen - logp_rejected)))\n            correct = (logp_chosen > logp_rejected).sum().item()\n\n            total_loss += loss.item()\n            total_correct += correct\n            total_samples += chosen_input_ids.size(0)\n\n    avg_loss = total_loss / len(dataloader)\n    avg_acc = total_correct / total_samples\n    return avg_loss, avg_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:44:24.606738Z","iopub.execute_input":"2025-08-11T11:44:24.607019Z","iopub.status.idle":"2025-08-11T11:44:25.801703Z","shell.execute_reply.started":"2025-08-11T11:44:24.606998Z","shell.execute_reply":"2025-08-11T11:44:25.800658Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1036636126.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import logging\nlogging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n\nepochs = 12\npatience = 2\nbeta = 0.2\n\npatience_counter = 0\nbest_epoch = 0\n\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\n\nbest_val_loss = float(\"inf\")\n\nfor epoch in range(epochs):\n    \n    print(f\"Epoch {epoch+1}/{epochs} \")\n\n    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler, device, beta)\n    val_loss, val_acc = validate(model, val_loader, device, beta)\n\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accuracies.append(train_acc)\n    val_accuracies.append(val_acc)\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\"\n    )\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_epoch = epoch + 1\n        patience_counter = 0\n        os.makedirs(\"results\", exist_ok=True)\n        model.save_pretrained(\"results/dpo_finetuned_gpt2\")\n        tokenizer.save_pretrained(\"results/dpo_finetuned_gpt2\")\n        print(f\"New best model saved (val_loss={val_loss:.4f}, val_acc={val_acc:.4f})\")\n    else:\n        patience_counter += 1\n        print(f\"No improvement ({patience_counter}/{patience})\")\n\n    if patience_counter >= patience:\n        print(\"!!! Early stopping triggered !!!\")\n        break\n\nprint(f\"\\n Loading best model from epoch {best_epoch} (val_loss={best_val_loss:.4f})\")\nmodel = AutoModelForCausalLM.from_pretrained(\"results/dpo_finetuned_gpt2\").to(device)\ntokenizer = GPT2Tokenizer.from_pretrained(\"results/dpo_finetuned_gpt2\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# График Loss\naxes[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\")\naxes[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\naxes[0].set_xlabel(\"Epoch\")\naxes[0].set_ylabel(\"Loss\")\naxes[0].set_title(\"DPO Training Loss\")\naxes[0].legend()\naxes[0].grid(True)\n\n# График Accuracy\naxes[1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label=\"Train Accuracy\")\naxes[1].plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\")\naxes[1].set_xlabel(\"Epoch\")\naxes[1].set_ylabel(\"Accuracy\")\naxes[1].set_title(\"DPO Training Accuracy\")\naxes[1].legend()\naxes[1].grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bertscore = evaluate.load(\"bertscore\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef generate_response(model, tokenizer, prompt, max_new_tokens=80):\n    prompt = prompt.strip()\n    if not prompt.endswith(\"Assistant:\"):\n        prompt += \"\\nAssistant:\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            min_new_tokens=8,\n            do_sample=True,\n            top_p=0.9,\n            temperature=1.0,\n            pad_token_id=tokenizer.eos_token_id,\n            eos_token_id=tokenizer.eos_token_id\n        )\n\n    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    answer = decoded[len(prompt):].strip() if decoded.startswith(prompt) else decoded.strip()\n    return answer\n\n# базовая модель\nbase_model_name = \"gpt2\"\nbase_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\nbase_model = AutoModelForCausalLM.from_pretrained(base_model_name).to(device)\nbase_model.eval()\n\n# оценка на подвыборке валидационных данных\nval_samples = random.sample(list(val_data_raw), min(10, len(val_data_raw)))\n\nreferences, base_outputs, tuned_outputs = [], [], []\n\nfor idx, sample in enumerate(val_samples):\n    prompt = sample['prompt_formatted']\n    ref_answer = sample['chosen_formatted']\n\n    tuned_out = generate_response(model, tokenizer, prompt)\n    base_out = generate_response(base_model, base_tokenizer, prompt)\n\n    print(f\"\\n=== Prompt {idx+1} ===\\n{prompt}\\n{'-'*40}\")\n    print(f\"Reference:\\n{ref_answer}\\n{'-'*40}\")\n    print(f\"Base model:\\n{base_out}\\n{'-'*40}\")\n    print(f\"Tuned model:\\n{tuned_out}\\n{'='*40}\")\n\n    references.append([ref_answer])\n    base_outputs.append(base_out)\n    tuned_outputs.append(tuned_out)\n\n# Подсчет BERTScore\nbert_results = bertscore.compute(\n    predictions=tuned_outputs,\n    references=[r[0] for r in references],\n    lang=\"en\"\n)\nmean_f1 = sum(bert_results[\"f1\"]) / len(bert_results[\"f1\"])\nprint(f\"\\nTuned BERTScore (mean F1): {mean_f1:.4f}\")\n\nresults = []\nfor i in range(len(val_samples)):\n    results.append({\n        \"prompt\": val_samples[i]['prompt_formatted'],\n        \"reference\": references[i][0],\n        \"base_output\": base_outputs[i],\n        \"tuned_output\": tuned_outputs[i]\n    })\n\nwith open(\"results/eval_results.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(results, f, ensure_ascii=False, indent=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}